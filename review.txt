###########################################
# No: 01                                  #
# Date: 18 May 2023                       #
# ID: ID 10300                            #
# Q Name: Premium vs Freemium             #
# Diff: Hard                              #
###########################################

WITH cte AS(
SELECT date,
    SUM(CASE paying_customer WHEN 'yes' THEN downloads END) paying,
    SUM(CASE paying_customer WHEN 'no' THEN downloads END) non_paying
FROM ms_user_dimension ud 
JOIN ms_acc_dimension ad ON ud.acc_id = ad.acc_id
JOIN ms_download_facts df ON ud.user_id = df.user_id
GROUP BY date
)
SELECT *
FROM cte
WHERE non_paying > paying
ORDER BY date;


###########################################
# No: 02                                  #
# Date: 19 May 2023                       #
# ID: ID 9894                             #
# Q Name: Employee and Manager Salaries   #
# Diff: Medium                            #
###########################################

SELECT e1.first_name, e1.salary
FROM employee e1, employee e2 
WHERE e1.manager_id = e2.id AND e1.salary + e1.bonus > e2.salary + e2.bonus;


###########################################
# No: 03                                  #
# Date: 05 June 2023                      #
# ID: ID 9942                             #
# Q Name: Largest Olympics                #
# Diff: Medium                            #
###########################################

SELECT games, num_ath
FROM (SELECT games, COUNT(DISTINCT(id)) num_ath, DENSE_RANK() OVER(ORDER BY COUNT(DISTINCT(id)) DESC) ranking
FROM olympics_athletes_events
GROUP BY games) s
WHERE ranking = 1


###########################################
# No: 04                                  #
# Date: 06 June 2023                      #
# ID: ID 10354                            #
# Q Name: Most Profitable Companies       #
# Diff: Medium                            #
###########################################

SELECT TOP 3 company, profits, DENSE_RANK() OVER(ORDER BY profits DESC) ranking
FROM forbes_global_2010_2014


###########################################
# No: 05                                  #
# Date: 07 June 2023                      #
# ID: ID 9814                             #
# Q Name: Counting Instances in Text      #
# Diff: Hard                              #
###########################################

SELECT 'bull' words, COUNT(contents) occurrences
FROM google_file_store
WHERE contents LIKE('%bull%')
UNION ALL
SELECT 'bear', COUNT(contents)
FROM google_file_store
WHERE contents LIKE('%bear%')
;


###########################################
# No: 06                                  #
# Date: 08 June 2023                      #
# ID: ID 10285                            #
# Q Name: Acceptance Rate By Date         #
# Diff: Medium                            #
###########################################

WITH s AS(
    SELECT * FROM fb_friend_requests
    WHERE action = 'sent'
), a AS(
    SELECT * FROM fb_friend_requests
    WHERE action = 'accepted'
)
SELECT s.date, 
    CAST(COUNT(a.action) AS FLOAT) / CAST(COUNT(s.action) AS FLOAT) accept_rate
FROM s
LEFT JOIN a
ON s.user_id_sender = a.user_id_sender AND 
   s.user_id_receiver = a.user_id_receiver
GROUP BY s.date
ORDER BY s.date
;

###########################################
# No: 07                                  #
# Date: 09 June 2023                      #
# ID: ID 9782                             #
# Q Name: Customer Revenue In March       #
# Diff: Medium                            #
###########################################

SELECT cust_id, SUM(total_order_cost) total_revenue
FROM orders
WHERE YEAR(order_date) = 2019 AND MONTH(order_date) = 3
GROUP BY cust_id
ORDER BY SUM(total_order_cost) DESC
;

###########################################
# No: 08                                  #
# Date: 13 June 2023                      #
# ID: ID 9781                             #
# Q Name: Find the rate of processed...   #
# Diff: Medium                            #
###########################################

- SELECT *, CASE WHEN processed = 'TRUE' THEN 1 ELSE 0 END
-- FROM facebook_complaints
-- 2/3 --> Average 

SELECT 
    type, 
    AVG(CAST(CASE WHEN processed = 'TRUE' THEN 1 ELSE 0 END AS FLOAT)) processed_rate
FROM facebook_complaints
GROUP BY type

###########################################
# No: 09                                  #
# Date: 14 June 2023                      #
# ID: ID 10064                            #
# Q Name: Highest Energy Consumption      #
# Diff: Medium                            #
###########################################

WITH c1 AS(
    SELECT * FROM fb_eu_energy
    UNION
    SELECT * FROM fb_asia_energy 
    UNION
    SELECT * FROM fb_na_energy 
), c2 AS(
    SELECT date, SUM(consumption) consumption, DENSE_RANK() OVER(ORDER BY SUM(consumption) DESC) ranking
    FROM c1
    GROUP BY date
)
SELECT date, consumption highest_total_energy_consumption
FROM c2
WHERE ranking = 1; 

###########################################
# No: 10                                  #
# Date: 15 June 2023                      #
# ID: ID 2005                             #
# Q Name: Share of Active Users           #
# Diff: Medium                            #
###########################################

SELECT 
    AVG(
        CAST(
            CASE 
            WHEN status = 'open' THEN 1 ELSE 0 
            END AS FLOAT)
        ) usa_active_user_rate
FROM fb_active_users
WHERE country = 'USA'

###########################################
# No: 11                                  #
# Date: 20 June 2023                      #
# ID: ID 10134                            #
# Q Name: Spam Posts                      #
# Diff: Medium                            #
###########################################

SELECT post_date,
    SUM(
        CASE 
            WHEN post_keywords LIKE LOWER('%spam%') THEN 1 ELSE 0 END
    ) * 100 / COUNT(*) spam_rate
FROM facebook_posts p
JOIN facebook_post_views v
ON p.post_id = v.post_id
GROUP BY post_date;



Find the rate of processed tickets for each type -- 10?
Highest Energy Consumption -- 13:45 


# 17 Aug 2023 #
Share of Active Users -- 07:00 
Spam Posts -- 04:36
***** Users By Average Session Time -- 19:28

# 18 Aug 2023 #
***** Users By Average Session Time -- 06:37
***** Popularity Percentage -- 19:47


# 21 Aug 2023 #
***** Popularity Percentage -- 08:14
***** Users By Average Session Time -- 08:45

# 23 Aug 2023 #
***** Premium vs Freemium -- 12:04
***** The Most Popular Client_Id Among Users Using Video and Voice Calls -- 36:39

# 24 Aug 2023 #
***** The Most Popular Client_Id Among Users Using Video and Voice Calls
***** Top percentile Fraud 18:43

# 25 Aug 2023 #
***** Top percentile Fraud -- 04:00
*** Highest Target Under Manager -- 04:15

***** The Most Popular Client_Id Among Users Using Video and Voice Calls -- 46:45
WITH c1 AS(
    SELECT 
        user_id, 
        client_id, 
-- Sum the count that shows how many times each user_id appears
        SUM(COUNT(user_id)) OVER(PARTITION BY user_id) user_cnt 
    FROM fact_events
    WHERE event_type IN ('video call received', 'video call sent', 'voice call received', 'voice call sent')
    GROUP BY user_id, client_id
), c2 AS(
-- total number of users' events
    SELECT user_id, COUNT(user_id) total_cnt
    FROM fact_events
    GROUP BY user_id
), c3 AS(
-- Join c1 and c2 and divide total_cnt by user_cnt to find the percentage of the specific events -> specific_events / total_events
    SELECT c1.user_id, client_id, CAST(user_cnt AS FLOAT) / total_cnt AS event_rate
    FROM c1
    JOIN c2 ON c1.user_id = c2.user_id
), c4 AS(
-- Rank client_id to find the most popular client_id
    SELECT client_id, COUNT(client_id) client_cnt,
        DENSE_RANK() OVER(ORDER BY COUNT(client_id) DESC) client_ranking
    FROM c3
    WHERE event_rate >= 0.5
    GROUP BY client_id
)
SELECT client_id
FROM c4
WHERE client_ranking = 1;

# 28 Aug 2023 #
*** Top percentile Fraud -- 08:40


###########################################
# Date: 06 February 2024                  #
# ID: 10351                               #
# Q Name: Activity Rank                   #
# Diff: Medium                            #
# Time: 05:03                             #
###########################################

SELECT from_user, 
    COUNT(from_user) cnt, 
    DENSE_RANK() OVER(ORDER BY COUNT(from_user) DESC, from_user) ranking
FROM google_gmail_emails
GROUP BY from_user;

###########################################
# Date: 08 February 2024                  #
# ID: 10351                               #
# Q Name: Finding User Purchases          #
# Diff: Medium                            #
# Time: 12:21                             #
###########################################

WITH c1 AS (
    SELECT user_id, 
    ABS(
        DATEDIFF(
            day,
            created_at,
            LAG(created_at, 1) OVER (PARTITION BY user_id ORDER BY created_at)
            )
        ) date_diff
    FROM amazon_transactions
) SELECT DISTINCT user_id
FROM c1
WHERE date_diff BETWEEN 0 AND 7;


###########################################
# Date: 09 February 2024                  #
# Q Name: New Products                    #
# Diff: Medium                            #
# Time: 07:20                             #
###########################################

SELECT company_name, 
    COUNT(CASE WHEN year = 2020 THEN company_name END ) - 
    COUNT(CASE WHEN year = 2019 THEN company_name END ) net_difference
FROM car_launches
GROUP BY company_name



###########################################
# Date: 12 February 2024                  #
# Q Name: Monthly Percentage Difference   #
# Diff: Hard                              #
# Time: 00:00                             #
###########################################

WITH cte1 AS(
    SELECT SUM(value) revenue, SUBSTRING(created_at, 1, 7) year_month
    FROM sf_transactions
    GROUP BY MONTH(created_at), SUBSTRING(created_at, 1, 7)
), cte2 AS(
    SELECT *, LAG(revenue,1) OVER(ORDER BY year_month) prev_mth_revenue
    FROM cte1
)
SELECT year_month, revenue, prev_mth_revenue,
    ROUND((CAST(revenue - prev_mth_revenue AS FLOAT) / prev_mth_revenue) * 100, 2) mom_percentage_change
FROM cte2;

###########################################
# Date: 13 February 2024                  
# Q Name: Salaries Differences            
# Diff: Easy???                           
# Time: 00:00                             
###########################################

WITH cte1 AS (
    SELECT department, MAX(salary) salary
    FROM db_employee e
    JOIN db_dept d
    ON e.department_id = d.id
    WHERE d.department = 'marketing' OR d.department = 'engineering'
    GROUP BY d.department
)
SELECT 
    (SELECT MAX(salary) FROM cte1 WHERE department = 'marketing'),
    (SELECT MAX(salary) FROM cte1 WHERE department = 'engineering')
FROM cte1

;


###########################################
# Date: 15 February 2024                  
# Q Name: Risky Projects          
# Diff: Medium                           
# Time: 31:25                             
###########################################

-- Problem with calculating the total employee expense 
-- Round to the next dollar amount -> ROUND() or CEILING()?? 
-- (SUM(salary) * (DATEDIFF(day, start_date, end_date)*1.0)) / 365 
-- (SUM((salary*1.0)/365) * (DATEDIFF(day, start_date, end_date)))


-- 1. Calculate the duration of each project
-- SELECT *
--     , DATEDIFF(day, start_date, end_date) duration
-- FROM linkedin_projects p 

-- 2. Calculate the daily? salary of emplyees -> salary/365
-- SELECT *,
--     -- salary/365 daily_rate
--     ROUND(CAST(salary AS FLOAT)/365, 1) daily_rate
-- FROM linkedin_employees e

-- 3. Check if the sum of employees' salaries is greater than the budget 

SELECT * 
FROM (
    SELECT 
        title, 
        budget,
            CEILING(
                (SUM(salary*1.0)/365 * (DATEDIFF(day, start_date, end_date)))
                -- (SUM(salary) * (DATEDIFF(day, start_date, end_date)*1.0)) / 365 
                )total_emp_expense
    FROM linkedin_projects p 
    JOIN linkedin_emp_projects l ON p.id = l.project_id
    JOIN linkedin_employees e ON e.id = l.emp_id
    GROUP BY title, budget, start_date, end_date) s1
WHERE budget < total_emp_expense 
ORDER BY title


# Practice #

-- CASE without NULL returns 
SELECT 
	season,
    date,
	home_goal,
	away_goal
FROM matches_italy
WHERE 
-- Exclude games not won by Bologna
	CASE 
		WHEN hometeam_id = 9857 AND home_goal > away_goal THEN 'Bologna Win'
		WHEN awayteam_id = 9857 AND away_goal > home_goal THEN 'Bologna Win' 
		END IS NOT NULL;

SELECT 
	c.name AS country,
    -- Count games from the 2012/2013 season
	COUNT(CASE WHEN m.season = '2012/2013' 
					-- ELSE values NULL
        	THEN m.id ELSE NULL END) AS matches_2012_2013 
FROM country AS cp
LEFT JOIN match AS m
ON c.id = m.country_id
GROUP BY country;


SELECT
	s.stage,
	ROUND(s.avg_goals, 2) avg_goal,
	(SELECT AVG(home_goal + away_goal)
	 FROM match
	 WHERE season = '2012/2013') overall_avg
FROM
	(SELECT
		stage,
		AVG(home_goal + away_goal) avg_goals 
	 FROM match
	 WHERE season = '2012/2013'
	 GROUP BY stage) AS s
WHERE s.avg_goals > (SELECT AVG(home_goal + away_goal)
			FROM match AS m
			WHERE s.stage > m.stage);


